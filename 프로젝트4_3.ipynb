{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ykSjvlR00U0Y"},"outputs":[],"source":["# pip install --upgrade python-telegram-bot"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":898,"status":"ok","timestamp":1722245447622,"user":{"displayName":"율이의꼬맹이","userId":"00187074085664188697"},"user_tz":-540},"id":"sfwN4MpIyT8K"},"outputs":[],"source":["import logging\n","import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from telegram import Update\n","from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes\n","from google.colab import drive\n","import os"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2779,"status":"ok","timestamp":1722245633275,"user":{"displayName":"율이의꼬맹이","userId":"00187074085664188697"},"user_tz":-540},"id":"i0QJW1jL1Bby","outputId":"9b99846e-5bb3-41c3-b5bd-d9649db108c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1722245635463,"user":{"displayName":"율이의꼬맹이","userId":"00187074085664188697"},"user_tz":-540},"id":"2tc8vDSl1sGP"},"outputs":[],"source":["model_path = '/content/drive/MyDrive/AI_chatbot(4th_prj)/sample_transformer_model.pth'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"caOqVNX3x7Pr"},"outputs":[],"source":["TOKEN = 'NEW'\n","\n","# 로깅 설정\n","logging.basicConfig(\n","    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n","    level=logging.INFO\n",")\n","logger = logging.getLogger(__name__)\n","\n","# 모델과 토크나이저 로드\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token = tokenizer.eos_token\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","model.to(device)\n","model.load_state_dict(torch.load(model_path))\n","model.eval()\n","\n","# 응답 생성 함수\n","def generate_response(question, tokenizer, model, max_length=512):\n","    inputs = tokenizer.encode(question, return_tensors='pt').to(device)\n","    with torch.no_grad():\n","        outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response\n","\n","# /start 명령어 처리 함수\n","async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n","    user = update.effective_user\n","    await update.message.reply_text(f'안녕하세요 {user.first_name}!\\n질문을 입력해 주세요.')\n","\n","# /help 명령어 처리 함수\n","async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n","    await update.message.reply_text('도움이 필요하시면 이 봇에게 질문을 하세요.')\n","\n","# 메시지 처리 함수\n","async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n","    user_input = update.message.text\n","    response = generate_response(user_input, tokenizer, model)\n","    await update.message.reply_text(response)\n","\n","# 메인 함수\n","def main() -> None:\n","    # 애플리케이션 빌더 생성\n","    app = ApplicationBuilder().token(TOKEN).build()\n","\n","    # 핸들러 등록\n","    app.add_handler(CommandHandler(\"start\", start))\n","    app.add_handler(CommandHandler(\"help\", help_command))\n","    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n","\n","    # 봇 시작\n","    app.run_polling()\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hOI9rLUe2xZr"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lzrDXOM2C3B1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6mXQVcNTmcB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KcwJDKCQCPAW"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1WGvzwYLC2Ie"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqzsETJ0C3Gn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSSgCzUXC3LB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qOE85nKC3Pc"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1c5frko3C3Th"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sin9bFBQC3Xn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lV91V4gGC3cB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEesfi24C3gX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1Q6uZmgC3kY"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8AvP2JpC3op"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PuiDkarqC3sf"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPlMTOFJY1fvw1TdtREn+6D","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
