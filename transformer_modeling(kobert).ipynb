{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPbL9fF8YETn0DL61RPPGQC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9ed819c132a04d0fbfdf9b3c1d37fca2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4d8ea9ff82940f8a208e8ce07cd807a","IPY_MODEL_229f555f78da4859a0652c1378a07168","IPY_MODEL_e7dae12b196b4d15bcbbc995a0351f19"],"layout":"IPY_MODEL_ef6221a3ab804afb8080ff0a115d0940"}},"e4d8ea9ff82940f8a208e8ce07cd807a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bae5b7730d2b40488a926281783575f1","placeholder":"​","style":"IPY_MODEL_55676205f0ca4d2caf601e9d07bd2e68","value":"tokenizer_config.json: 100%"}},"229f555f78da4859a0652c1378a07168":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d566fe1b3a4470c8c4711dd9f8c73a4","max":432,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5fe10edfd884718909210cda12b5298","value":432}},"e7dae12b196b4d15bcbbc995a0351f19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_281647463dd04eb4a73abca9ec4a5977","placeholder":"​","style":"IPY_MODEL_b0cc7aeaf0d2403baa6b19b2fdcba56c","value":" 432/432 [00:00&lt;00:00, 16.3kB/s]"}},"ef6221a3ab804afb8080ff0a115d0940":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bae5b7730d2b40488a926281783575f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55676205f0ca4d2caf601e9d07bd2e68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d566fe1b3a4470c8c4711dd9f8c73a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5fe10edfd884718909210cda12b5298":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"281647463dd04eb4a73abca9ec4a5977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0cc7aeaf0d2403baa6b19b2fdcba56c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"734acd8635a341cc8c52ad1957f941d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d98f95e0ba0f43b2a042d72d180bd887","IPY_MODEL_925ea8c2835b42bfa35fb58decc5cbbf","IPY_MODEL_9dd2260486cf4d7f9735c9ffea018470"],"layout":"IPY_MODEL_0f78d1dc3276479ba6763ab67ca00173"}},"d98f95e0ba0f43b2a042d72d180bd887":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efb04199d08e465ca9f716225d278ee2","placeholder":"​","style":"IPY_MODEL_e1b2b79e81a04e7eb957064637cfe68c","value":"spiece.model: 100%"}},"925ea8c2835b42bfa35fb58decc5cbbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d03245247f4f486a8766a03a4f77d823","max":371427,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0c6e672fc0145c2b78206b8843ffdcb","value":371427}},"9dd2260486cf4d7f9735c9ffea018470":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_130f26ed7fba46ad9bf8b9b3b8c994c5","placeholder":"​","style":"IPY_MODEL_036f4ce83f99419c9c6cf6965ad02de8","value":" 371k/371k [00:00&lt;00:00, 1.72MB/s]"}},"0f78d1dc3276479ba6763ab67ca00173":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efb04199d08e465ca9f716225d278ee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1b2b79e81a04e7eb957064637cfe68c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d03245247f4f486a8766a03a4f77d823":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0c6e672fc0145c2b78206b8843ffdcb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"130f26ed7fba46ad9bf8b9b3b8c994c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"036f4ce83f99419c9c6cf6965ad02de8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3511632780ab479b8c0ca22f0b1bf048":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a852e11a320143c6b4a26294166aaa41","IPY_MODEL_b3c69774f6924fa1b2e864f472b9f5e1","IPY_MODEL_f806710f084d4f2abee27c4e96d0fb30"],"layout":"IPY_MODEL_d08be6b6e81d4d5c81413747a77fbae4"}},"a852e11a320143c6b4a26294166aaa41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c307e8908b1c46debd9eef80aa22e8e4","placeholder":"​","style":"IPY_MODEL_2e0a8ce9d2de49979436a5bae41a06fb","value":"special_tokens_map.json: 100%"}},"b3c69774f6924fa1b2e864f472b9f5e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_098f6e8178a7490ab00850cf53afff38","max":244,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25f2f82bd470466899ce7210f024c9ca","value":244}},"f806710f084d4f2abee27c4e96d0fb30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2726db88fe0448c68680094cbad34590","placeholder":"​","style":"IPY_MODEL_0ceec055a8bc428b95ae4424deefcf36","value":" 244/244 [00:00&lt;00:00, 6.31kB/s]"}},"d08be6b6e81d4d5c81413747a77fbae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c307e8908b1c46debd9eef80aa22e8e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e0a8ce9d2de49979436a5bae41a06fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"098f6e8178a7490ab00850cf53afff38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25f2f82bd470466899ce7210f024c9ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2726db88fe0448c68680094cbad34590":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ceec055a8bc428b95ae4424deefcf36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.utils.data import DataLoader, TensorDataset\n","import os\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from google.colab import drive"],"metadata":{"id":"JJBhvcPiWB_h","executionInfo":{"status":"ok","timestamp":1721967430489,"user_tz":-540,"elapsed":553,"user":{"displayName":"gosling","userId":"04922823008265108443"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUCQ2j5LZpTB","executionInfo":{"status":"ok","timestamp":1721967454314,"user_tz":-540,"elapsed":23200,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"ac43413d-0e95-4bf5-aa5e-cd00b892150a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/chatbot-project')"]},{"cell_type":"code","source":["my_data = pd.read_csv('./preprocessed_qna_final.csv')\n","my_data.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"oeezA6IiZsUE","executionInfo":{"status":"ok","timestamp":1721967456099,"user_tz":-540,"elapsed":1787,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"a29feb82-c5ac-4bdb-e109-4db3a0a1c28b"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 questions                                            answers\n","0   대성각의 대표적인 메뉴를 알 수 있나요?                            대성각의 메뉴에는 짜장면, 짬뽕이 있습니다\n","1      대성각의 영업시간은 어떻게 되나요?                  대성각의 영업시간은 11:00 - 15:00/21:00입니다\n","2       대성각의 연락처를 알 수 있나요?                           대성각의 연락처는 02-356-2194입니다\n","3    대성각에 인접한 시설을 알 수 있나요?  대성각에 인접한 시설에는 역촌역 3번출구, 그림나라아동미술, 메리피아노음악교습소가 ...\n","4       대성각의 휴무일을 알 수 있나요?                                대성각의 휴무일은 매주 일요일입니다\n","5        대성각의 위치를 알 수 있나요?                           대성각의 위치는 서울 은평구 녹번로 7입니다\n","6          대성각의 주차시설이 있나요?                                    대성각의 주차시설은 없습니다\n","7  대성각의 주차시설이 있는지 알 수 있나요?                                    대성각의 주차시설은 없습니다\n","8        대성각에 인접한 시설이 있나요?  대성각에 인접한 시설에는 역촌역 3번출구, 그림나라아동미술, 메리피아노음악교습소가 ...\n","9     대성각의 주요 메뉴를 알 수 있나요?                            대성각의 메뉴에는 짜장면, 짬뽕이 있습니다"],"text/html":["\n","  <div id=\"df-f8ffd385-2198-44a6-8c37-25befea3dc31\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>questions</th>\n","      <th>answers</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>대성각의 대표적인 메뉴를 알 수 있나요?</td>\n","      <td>대성각의 메뉴에는 짜장면, 짬뽕이 있습니다</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>대성각의 영업시간은 어떻게 되나요?</td>\n","      <td>대성각의 영업시간은 11:00 - 15:00/21:00입니다</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>대성각의 연락처를 알 수 있나요?</td>\n","      <td>대성각의 연락처는 02-356-2194입니다</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>대성각에 인접한 시설을 알 수 있나요?</td>\n","      <td>대성각에 인접한 시설에는 역촌역 3번출구, 그림나라아동미술, 메리피아노음악교습소가 ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>대성각의 휴무일을 알 수 있나요?</td>\n","      <td>대성각의 휴무일은 매주 일요일입니다</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>대성각의 위치를 알 수 있나요?</td>\n","      <td>대성각의 위치는 서울 은평구 녹번로 7입니다</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>대성각의 주차시설이 있나요?</td>\n","      <td>대성각의 주차시설은 없습니다</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>대성각의 주차시설이 있는지 알 수 있나요?</td>\n","      <td>대성각의 주차시설은 없습니다</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>대성각에 인접한 시설이 있나요?</td>\n","      <td>대성각에 인접한 시설에는 역촌역 3번출구, 그림나라아동미술, 메리피아노음악교습소가 ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>대성각의 주요 메뉴를 알 수 있나요?</td>\n","      <td>대성각의 메뉴에는 짜장면, 짬뽕이 있습니다</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8ffd385-2198-44a6-8c37-25befea3dc31')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f8ffd385-2198-44a6-8c37-25befea3dc31 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f8ffd385-2198-44a6-8c37-25befea3dc31');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8d34c1ac-de5f-444b-ab10-ee950ad5b122\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d34c1ac-de5f-444b-ab10-ee950ad5b122')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8d34c1ac-de5f-444b-ab10-ee950ad5b122 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"my_data","summary":"{\n  \"name\": \"my_data\",\n  \"rows\": 26691,\n  \"fields\": [\n    {\n      \"column\": \"questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21949,\n        \"samples\": [\n          \"\\ud788\\ub4e0\\ud50c\\ub798\\ub2db\\uc758 \\uc704\\uce58\\ub294 \\uc5b4\\ub5bb\\uac8c \\ub418\\ub098\\uc694?\",\n          \"\\uba74\\uace1\\ub2f9 \\uc7a5\\uc548\\uc810\\uc758 \\uc5f0\\ub77d\\ucc98\\ub97c \\uc54c \\uc218 \\uc788\\ub098\\uc694?\",\n          \"\\uc644\\ub3c4\\uc9d1\\uc758 \\uc8fc\\uc694 \\uba54\\ub274\\ub97c \\uc54c \\uc218 \\uc788\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16547,\n        \"samples\": [\n          \"\\uba85\\ub95c\\uc9c4\\uc0ac\\uac08\\ube44 \\uc2e0\\uc6d4\\uc810\\uc758 \\uc8fc\\ucc28\\uc2dc\\uc124\\uc740 \\uc788\\uc2b5\\ub2c8\\ub2e4\",\n          \"\\uae4c\\ub808\\ud3ec\\uba38\\uc758 \\uc8fc\\ucc28\\uc2dc\\uc124\\uc740 \\uc788\\uc2b5\\ub2c8\\ub2e4\",\n          \"\\ubc84\\ub4e4\\uace8\\ucd94\\uc5b4\\ud0d5\\uc758 \\uc8fc\\ucc28\\uc2dc\\uc124\\uc740 \\uc788\\uc2b5\\ub2c8\\ub2e4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZx4cL00wBuZ","executionInfo":{"status":"ok","timestamp":1721967462047,"user_tz":-540,"elapsed":5952,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"bd6ceff0-3fb2-4f2a-c90c-0f980e7eb41c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-b3dxkno6/kobert-tokenizer_43745fec09ed4251b20b012b79082219\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-b3dxkno6/kobert-tokenizer_43745fec09ed4251b20b012b79082219\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: kobert_tokenizer\n","  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4632 sha256=5ad1af24f63f19430bd6fac174740feb46554883b899511cca5ec3382308b2a1\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ltg_9r0_/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n","Successfully built kobert_tokenizer\n","Installing collected packages: kobert_tokenizer\n","Successfully installed kobert_tokenizer-0.1\n"]}]},{"cell_type":"code","source":["from kobert_tokenizer import KoBERTTokenizer\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","tokenizer.encode(\"대성각에 인접한 시설이 있나요?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554,"referenced_widgets":["9ed819c132a04d0fbfdf9b3c1d37fca2","e4d8ea9ff82940f8a208e8ce07cd807a","229f555f78da4859a0652c1378a07168","e7dae12b196b4d15bcbbc995a0351f19","ef6221a3ab804afb8080ff0a115d0940","bae5b7730d2b40488a926281783575f1","55676205f0ca4d2caf601e9d07bd2e68","8d566fe1b3a4470c8c4711dd9f8c73a4","b5fe10edfd884718909210cda12b5298","281647463dd04eb4a73abca9ec4a5977","b0cc7aeaf0d2403baa6b19b2fdcba56c","734acd8635a341cc8c52ad1957f941d8","d98f95e0ba0f43b2a042d72d180bd887","925ea8c2835b42bfa35fb58decc5cbbf","9dd2260486cf4d7f9735c9ffea018470","0f78d1dc3276479ba6763ab67ca00173","efb04199d08e465ca9f716225d278ee2","e1b2b79e81a04e7eb957064637cfe68c","d03245247f4f486a8766a03a4f77d823","f0c6e672fc0145c2b78206b8843ffdcb","130f26ed7fba46ad9bf8b9b3b8c994c5","036f4ce83f99419c9c6cf6965ad02de8","3511632780ab479b8c0ca22f0b1bf048","a852e11a320143c6b4a26294166aaa41","b3c69774f6924fa1b2e864f472b9f5e1","f806710f084d4f2abee27c4e96d0fb30","d08be6b6e81d4d5c81413747a77fbae4","c307e8908b1c46debd9eef80aa22e8e4","2e0a8ce9d2de49979436a5bae41a06fb","098f6e8178a7490ab00850cf53afff38","25f2f82bd470466899ce7210f024c9ca","2726db88fe0448c68680094cbad34590","0ceec055a8bc428b95ae4424deefcf36"]},"id":"gaVU-ojBaIcL","executionInfo":{"status":"ok","timestamp":1721967466464,"user_tz":-540,"elapsed":4420,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"3d0b2a8e-689e-476c-b509-f9e98101fdaa"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ed819c132a04d0fbfdf9b3c1d37fca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/371k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"734acd8635a341cc8c52ad1957f941d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3511632780ab479b8c0ca22f0b1bf048"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"]},{"output_type":"execute_result","data":{"text/plain":["[2,\n"," 1633,\n"," 6573,\n"," 5336,\n"," 6896,\n"," 3758,\n"," 7225,\n"," 7828,\n"," 2981,\n"," 7096,\n"," 3854,\n"," 5655,\n"," 6999,\n"," 258,\n"," 3]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["questions = my_data['questions']\n","answers = my_data['answers']\n","\n","# # 토큰화\n","question_tokens = [tokenizer.encode(q, add_special_tokens=True) for q in questions]\n","answer_tokens = [tokenizer.encode(a, add_special_tokens=True) for a in answers]\n","question_tokens[:5], answer_tokens[:5]"],"metadata":{"id":"6gc8txwZbanC","executionInfo":{"status":"ok","timestamp":1721967483772,"user_tz":-540,"elapsed":17311,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"739ef25c-ccf6-4c44-b530-873a6af78150"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([[2,\n","   1633,\n","   6573,\n","   5336,\n","   7095,\n","   1678,\n","   2017,\n","   6116,\n","   3166,\n","   2872,\n","   3854,\n","   5655,\n","   6999,\n","   258,\n","   3],\n","  [2,\n","   1633,\n","   6573,\n","   5336,\n","   7095,\n","   3382,\n","   6706,\n","   7086,\n","   3225,\n","   1763,\n","   5655,\n","   6999,\n","   258,\n","   3],\n","  [2,\n","   1633,\n","   6573,\n","   5336,\n","   7095,\n","   3343,\n","   7416,\n","   6116,\n","   3166,\n","   2872,\n","   3854,\n","   5655,\n","   6999,\n","   258,\n","   3],\n","  [2,\n","   1633,\n","   6573,\n","   5336,\n","   6896,\n","   3758,\n","   7225,\n","   7828,\n","   2981,\n","   7088,\n","   3166,\n","   2872,\n","   3854,\n","   5655,\n","   6999,\n","   258,\n","   3],\n","  [2,\n","   1633,\n","   6573,\n","   5336,\n","   7095,\n","   5191,\n","   6228,\n","   7126,\n","   7088,\n","   3166,\n","   2872,\n","   3854,\n","   5655,\n","   6999,\n","   258,\n","   3]],\n"," [[2,\n","   1633,\n","   6573,\n","   5336,\n","   7095,\n","   2017,\n","   6900,\n","   4396,\n","   7178,\n","   6198,\n","   46,\n","   517,\n","   7367,\n","   6481,\n","   7096,\n","   3867,\n","   3],\n","  [2,\n","   1633,\n","   6573,\n","   5336,\n","   7095,\n","   3382,\n","   6706,\n","   7086,\n","   538,\n","   251,\n","   524,\n","   543,\n","   251,\n","   59,\n","   133,\n","   251,\n","   7139,\n","   3],\n","  [2,\n","   1633,\n","   6573,\n","   5336,\n","   7095,\n","   3343,\n","   7416,\n","   5760,\n","   517,\n","   84,\n","   142,\n","   184,\n","   47,\n","   133,\n","   243,\n","   7139,\n","   3],\n","  [2,\n","   1633,\n","   6573,\n","   5336,\n","   6896,\n","   3758,\n","   7225,\n","   7828,\n","   2981,\n","   6900,\n","   3322,\n","   7449,\n","   6926,\n","   589,\n","   6328,\n","   7468,\n","   5495,\n","   46,\n","   1212,\n","   5659,\n","   6797,\n","   5872,\n","   6255,\n","   6645,\n","   46,\n","   2016,\n","   6122,\n","   7769,\n","   5725,\n","   7090,\n","   5488,\n","   6699,\n","   6607,\n","   5330,\n","   3867,\n","   3],\n","  [2,\n","   1633,\n","   6573,\n","   5336,\n","   7095,\n","   5191,\n","   6228,\n","   7126,\n","   7086,\n","   1999,\n","   3803,\n","   6999,\n","   7126,\n","   7139,\n","   3]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["cls_token_id = tokenizer.cls_token_id\n","sep_token_id = tokenizer.sep_token_id\n","pad_token_id = tokenizer.pad_token_id\n","print(cls_token_id, sep_token_id, pad_token_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTjGx_pxU2Z_","executionInfo":{"status":"ok","timestamp":1721967483772,"user_tz":-540,"elapsed":13,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"f22bf810-19f7-4dd7-b256-62f7c9b3e920"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2 3 1\n"]}]},{"cell_type":"code","source":["# 토큰화된 리스트를 PyTorch 텐서로 변환\n","questions_tensors = [torch.tensor(t, dtype=torch.long) for t in question_tokens]\n","answers_tensors = [torch.tensor(t, dtype=torch.long) for t in answer_tokens]\n","questions_tensors[:5], answers_tensors[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t8_b1tSrVYdI","executionInfo":{"status":"ok","timestamp":1721967484443,"user_tz":-540,"elapsed":683,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"49ee957e-1d33-4c7d-9fa0-ba885279c100"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([tensor([   2, 1633, 6573, 5336, 7095, 1678, 2017, 6116, 3166, 2872, 3854, 5655,\n","          6999,  258,    3]),\n","  tensor([   2, 1633, 6573, 5336, 7095, 3382, 6706, 7086, 3225, 1763, 5655, 6999,\n","           258,    3]),\n","  tensor([   2, 1633, 6573, 5336, 7095, 3343, 7416, 6116, 3166, 2872, 3854, 5655,\n","          6999,  258,    3]),\n","  tensor([   2, 1633, 6573, 5336, 6896, 3758, 7225, 7828, 2981, 7088, 3166, 2872,\n","          3854, 5655, 6999,  258,    3]),\n","  tensor([   2, 1633, 6573, 5336, 7095, 5191, 6228, 7126, 7088, 3166, 2872, 3854,\n","          5655, 6999,  258,    3])],\n"," [tensor([   2, 1633, 6573, 5336, 7095, 2017, 6900, 4396, 7178, 6198,   46,  517,\n","          7367, 6481, 7096, 3867,    3]),\n","  tensor([   2, 1633, 6573, 5336, 7095, 3382, 6706, 7086,  538,  251,  524,  543,\n","           251,   59,  133,  251, 7139,    3]),\n","  tensor([   2, 1633, 6573, 5336, 7095, 3343, 7416, 5760,  517,   84,  142,  184,\n","            47,  133,  243, 7139,    3]),\n","  tensor([   2, 1633, 6573, 5336, 6896, 3758, 7225, 7828, 2981, 6900, 3322, 7449,\n","          6926,  589, 6328, 7468, 5495,   46, 1212, 5659, 6797, 5872, 6255, 6645,\n","            46, 2016, 6122, 7769, 5725, 7090, 5488, 6699, 6607, 5330, 3867,    3]),\n","  tensor([   2, 1633, 6573, 5336, 7095, 5191, 6228, 7126, 7086, 1999, 3803, 6999,\n","          7126, 7139,    3])])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# 패딩을 위한 최대 길이 결정\n","questions_max_length = max(tensor.size(0) for tensor in questions_tensors)\n","answers_max_length = max(tensor.size(0) for tensor in answers_tensors)\n","max_length = max(questions_max_length, answers_max_length)\n","max_length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3FlISLXcVaE9","executionInfo":{"status":"ok","timestamp":1721967484443,"user_tz":-540,"elapsed":5,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"a1177afd-73ad-4ed4-ea67-a6f85730c3d3"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["71"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# 패딩 함수\n","def pad_or_truncate(tensors, max_length, pad_token_id):\n","    padded_tensors = []\n","    for tensor in tensors:\n","        if tensor.size(0) < max_length:\n","            padded_tensor = torch.cat([tensor, torch.tensor([pad_token_id] * (max_length - tensor.size(0)), dtype=torch.long)])\n","        else:\n","            padded_tensor = tensor[:max_length]\n","        padded_tensors.append(padded_tensor)\n","    return pad_sequence(padded_tensors, batch_first=True)\n","\n","# 패딩 및 트렁케이팅 적용\n","questions_padded = pad_or_truncate(questions_tensors, max_length, pad_token_id=pad_token_id)\n","answers_padded = pad_or_truncate(answers_tensors, max_length, pad_token_id=pad_token_id)\n","\n","# 패딩된 텐서의 모양\n","print(\"Padded Questions Shape:\", questions_padded.shape)\n","print(\"Padded Answers Shape:\", answers_padded.shape)\n","print(\"Padded Questions head:\", questions_padded[:5])\n","print(\"Padded Answers head:\", answers_padded[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WT_1y-h2Wbsx","executionInfo":{"status":"ok","timestamp":1721967486671,"user_tz":-540,"elapsed":2230,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"84d84d83-106a-4339-8a5e-9fcb70bc140c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Padded Questions Shape: torch.Size([26691, 71])\n","Padded Answers Shape: torch.Size([26691, 71])\n","Padded Questions head: tensor([[   2, 1633, 6573, 5336, 7095, 1678, 2017, 6116, 3166, 2872, 3854, 5655,\n","         6999,  258,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","        [   2, 1633, 6573, 5336, 7095, 3382, 6706, 7086, 3225, 1763, 5655, 6999,\n","          258,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","        [   2, 1633, 6573, 5336, 7095, 3343, 7416, 6116, 3166, 2872, 3854, 5655,\n","         6999,  258,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","        [   2, 1633, 6573, 5336, 6896, 3758, 7225, 7828, 2981, 7088, 3166, 2872,\n","         3854, 5655, 6999,  258,    3,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","        [   2, 1633, 6573, 5336, 7095, 5191, 6228, 7126, 7088, 3166, 2872, 3854,\n","         5655, 6999,  258,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]])\n","Padded Answers head: tensor([[   2, 1633, 6573, 5336, 7095, 2017, 6900, 4396, 7178, 6198,   46,  517,\n","         7367, 6481, 7096, 3867,    3,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","        [   2, 1633, 6573, 5336, 7095, 3382, 6706, 7086,  538,  251,  524,  543,\n","          251,   59,  133,  251, 7139,    3,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","        [   2, 1633, 6573, 5336, 7095, 3343, 7416, 5760,  517,   84,  142,  184,\n","           47,  133,  243, 7139,    3,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","        [   2, 1633, 6573, 5336, 6896, 3758, 7225, 7828, 2981, 6900, 3322, 7449,\n","         6926,  589, 6328, 7468, 5495,   46, 1212, 5659, 6797, 5872, 6255, 6645,\n","           46, 2016, 6122, 7769, 5725, 7090, 5488, 6699, 6607, 5330, 3867,    3,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","        [   2, 1633, 6573, 5336, 7095, 5191, 6228, 7126, 7086, 1999, 3803, 6999,\n","         7126, 7139,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1]])\n"]}]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=max_length):\n","        super(PositionalEncoding, self).__init__()\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:, :x.size(1), :]\n","        return x"],"metadata":{"id":"kAuER4vHYGKq","executionInfo":{"status":"ok","timestamp":1721985079262,"user_tz":-540,"elapsed":518,"user":{"displayName":"gosling","userId":"04922823008265108443"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["class TransformerModel(nn.Module):\n","    def __init__(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, vocab_size, max_len=max_length):\n","        super(TransformerModel, self).__init__()\n","        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead,\n","                                          num_encoder_layers=num_encoder_layers,\n","                                          num_decoder_layers=num_decoder_layers,\n","                                          dim_feedforward=dim_feedforward,\n","                                          batch_first=True)\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)\n","        self.pos_encoder = PositionalEncoding(d_model, max_len)\n","        self.fc_out = nn.Linear(d_model, vocab_size)\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None):\n","        src = self.embedding(src)\n","        tgt = self.embedding(tgt)\n","        src = self.pos_encoder(src)\n","        tgt = self.pos_encoder(tgt)\n","\n","        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n","\n","        output = self.transformer(src, tgt,\n","                                  tgt_mask=tgt_mask,\n","                                  src_key_padding_mask=src_key_padding_mask,\n","                                  tgt_key_padding_mask=tgt_key_padding_mask)\n","        return self.fc_out(output)"],"metadata":{"id":"BeywinYmaJg1","executionInfo":{"status":"ok","timestamp":1721985084886,"user_tz":-540,"elapsed":512,"user":{"displayName":"gosling","userId":"04922823008265108443"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=4, verbose=False):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.best_loss = float('inf')\n","        self.counter = 0\n","        self.stopped_early = False\n","\n","    def __call__(self, train_loss, model):\n","        if train_loss < self.best_loss:\n","            self.best_loss = train_loss\n","            self.counter = 0\n","            torch.save(model.state_dict(), 'best_model.pth')\n","        else:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'Training loss did not improve. Counter: {self.counter}/{self.patience}')\n","            if self.counter >= self.patience:\n","                self.stopped_early = True\n","                if self.verbose:\n","                    print('Early stopping triggered.')"],"metadata":{"id":"aFHyXQuMYbEN","executionInfo":{"status":"ok","timestamp":1721985087469,"user_tz":-540,"elapsed":585,"user":{"displayName":"gosling","userId":"04922823008265108443"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Using device:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aiVzKv7-Yic1","executionInfo":{"status":"ok","timestamp":1721985088055,"user_tz":-540,"elapsed":4,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"ebc132fd-27d8-4925-82d2-12eec7be46fc"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["vocab_size = tokenizer.vocab_size\n","d_model = 512\n","nhead = 8\n","num_encoder_layers = 6\n","num_decoder_layers = 6\n","dim_feedforward = 2048"],"metadata":{"id":"A2OWiJNbaY4g","executionInfo":{"status":"ok","timestamp":1721985009971,"user_tz":-540,"elapsed":514,"user":{"displayName":"gosling","userId":"04922823008265108443"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 생성\n","dataset = TensorDataset(questions_padded, answers_padded)\n","dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=2, pin_memory=True)\n","\n","# 모델, 옵티마이저 생성\n","model = TransformerModel(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers,\n","                         num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward,\n","                         vocab_size=vocab_size, max_len=max_length)\n","\n","model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n","\n","early_stopping = EarlyStopping(patience=4, verbose=True)\n","\n","scaler = GradScaler()\n","\n","# 학습\n","num_epochs = 50\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","\n","    for batch in dataloader:\n","        src_batch, tgt_batch = batch\n","\n","        src_batch = src_batch.to(device)\n","        tgt_batch = tgt_batch.to(device)\n","\n","        tgt_input = tgt_batch[:, :-1]\n","        tgt_output = tgt_batch[:, 1:]\n","\n","        src_key_padding_mask = (src_batch == pad_token_id).to(device)\n","        tgt_key_padding_mask = (tgt_input == pad_token_id).to(device)\n","\n","        optimizer.zero_grad()\n","\n","        with autocast():\n","            output = model(src_batch, tgt_input,\n","                       src_key_padding_mask=src_key_padding_mask,\n","                       tgt_key_padding_mask=tgt_key_padding_mask)\n","            loss = criterion(output.contiguous().view(-1, vocab_size), tgt_output.contiguous().view(-1))\n","\n","        scaler.scale(loss).backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        epoch_loss += loss.item()\n","\n","    avg_loss = epoch_loss / len(dataloader)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.6f}\")\n","\n","    early_stopping(avg_loss, model)\n","    if early_stopping.stopped_early:\n","        break\n","\n","print(\"Training complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7g-fPO2p4lH","executionInfo":{"status":"ok","timestamp":1721988353980,"user_tz":-540,"elapsed":3143921,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"4b349150-be8a-44e9-d43b-e71bb91dbc40"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Train Loss: 5.838479\n","Epoch 2/50, Train Loss: 3.461761\n","Epoch 3/50, Train Loss: 2.546593\n","Epoch 4/50, Train Loss: 2.078056\n","Epoch 5/50, Train Loss: 1.715536\n","Epoch 6/50, Train Loss: 1.421165\n","Epoch 7/50, Train Loss: 1.185781\n","Epoch 8/50, Train Loss: 1.004832\n","Epoch 9/50, Train Loss: 0.873679\n","Epoch 10/50, Train Loss: 0.766108\n","Epoch 11/50, Train Loss: 0.678648\n","Epoch 12/50, Train Loss: 0.601871\n","Epoch 13/50, Train Loss: 0.531182\n","Epoch 14/50, Train Loss: 0.467397\n","Epoch 15/50, Train Loss: 0.412278\n","Epoch 16/50, Train Loss: 0.360238\n","Epoch 17/50, Train Loss: 0.316889\n","Epoch 18/50, Train Loss: 0.277136\n","Epoch 19/50, Train Loss: 0.243517\n","Epoch 20/50, Train Loss: 0.187528\n","Epoch 21/50, Train Loss: 0.156901\n","Epoch 22/50, Train Loss: 0.142929\n","Epoch 23/50, Train Loss: 0.131215\n","Epoch 24/50, Train Loss: 0.123601\n","Epoch 25/50, Train Loss: 0.116124\n","Epoch 26/50, Train Loss: 0.110995\n","Epoch 27/50, Train Loss: 0.106409\n","Epoch 28/50, Train Loss: 0.101853\n","Epoch 29/50, Train Loss: 0.098365\n","Epoch 30/50, Train Loss: 0.095433\n","Epoch 31/50, Train Loss: 0.093408\n","Epoch 32/50, Train Loss: 0.090980\n","Epoch 33/50, Train Loss: 0.089659\n","Epoch 34/50, Train Loss: 0.087021\n","Epoch 35/50, Train Loss: 0.085269\n","Epoch 36/50, Train Loss: 0.083499\n","Epoch 37/50, Train Loss: 0.082482\n","Epoch 38/50, Train Loss: 0.080742\n","Epoch 39/50, Train Loss: 0.072382\n","Epoch 40/50, Train Loss: 0.066012\n","Epoch 41/50, Train Loss: 0.065041\n","Epoch 42/50, Train Loss: 0.063720\n","Epoch 43/50, Train Loss: 0.063349\n","Epoch 44/50, Train Loss: 0.062708\n","Epoch 45/50, Train Loss: 0.061995\n","Epoch 46/50, Train Loss: 0.061361\n","Epoch 47/50, Train Loss: 0.061057\n","Epoch 48/50, Train Loss: 0.060592\n","Epoch 49/50, Train Loss: 0.060061\n","Epoch 50/50, Train Loss: 0.059631\n","Training complete!\n"]}]},{"cell_type":"code","source":["def generate_text(model, src, tokenizer, max_length=max_length, device='cuda'):\n","    src = src.to(device)\n","    src_key_padding_mask = (src == pad_token_id).to(device)\n","\n","    with torch.no_grad():\n","        tgt_input = torch.tensor([[cls_token_id]], device=device, dtype=torch.long)\n","        for _ in range(max_length):\n","            tgt_key_padding_mask = (tgt_input == pad_token_id).to(device)\n","\n","            output = model(src, tgt_input, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n","            output_probs = F.softmax(output[:, -1, :], dim=-1)\n","            next_token = torch.argmax(output_probs, dim=-1)\n","\n","            tgt_input = torch.cat((tgt_input, next_token.unsqueeze(0)), dim=1)\n","\n","            if next_token.item() == sep_token_id:\n","                break\n","\n","    return tgt_input[:, 1:].squeeze(0)  # Remove CLS token"],"metadata":{"id":"ZC1QDY4abHgG","executionInfo":{"status":"ok","timestamp":1721988397342,"user_tz":-540,"elapsed":1258,"user":{"displayName":"gosling","userId":"04922823008265108443"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["def decode_output(output_tokens, tokenizer):\n","    tokens = tokenizer.convert_ids_to_tokens(output_tokens)\n","    return tokenizer.convert_tokens_to_string([token for token in tokens if token not in [tokenizer.pad_token, tokenizer.sep_token]])"],"metadata":{"id":"3PkRTg5HbKAY","executionInfo":{"status":"ok","timestamp":1721988397342,"user_tz":-540,"elapsed":2,"user":{"displayName":"gosling","userId":"04922823008265108443"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["# 평가\n","model.eval()\n","generated_texts = []\n","target_texts = []\n","\n","try:\n","    with torch.no_grad():\n","        # 첫 번째 배치만 가져옵니다\n","        batch = next(iter(dataloader))\n","        src_batch, tgt_batch = batch\n","        src_batch = src_batch.to(device)\n","        tgt_batch = tgt_batch.to(device)\n","\n","        for i, (src_single, tgt_single) in enumerate(zip(src_batch, tgt_batch)):\n","            # Beam Search를 사용하여 텍스트 생성\n","            generated = generate_text(model, src_single.unsqueeze(0), tokenizer, max_length=max_length, device=device)\n","            input_text = tokenizer.decode(src_single.cpu().numpy(), skip_special_tokens=True)\n","            predicted_text = decode_output(generated.cpu().numpy(), tokenizer)  # 이 부분에서 차원 확인\n","            target_text = tokenizer.decode(tgt_single.cpu().numpy(), skip_special_tokens=True)\n","\n","            print(f\"\\nSample {i+1}:\")\n","            print(f\"Input: {input_text}\")\n","            print(f\"Predicted: {predicted_text}\")\n","            print(f\"Target: {target_text}\")\n","\n","            generated_texts.append(predicted_text)\n","            target_texts.append(target_text)\n","\n","            if i == 9:\n","                break\n","\n","except Exception as e:\n","    print(f\"An error occurred during evaluation: {str(e)}\")\n","\n","print(\"Evaluation complete!\")"],"metadata":{"id":"d_WeV_iP9MWE","executionInfo":{"status":"ok","timestamp":1721988400920,"user_tz":-540,"elapsed":3000,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6aff7e8d-8553-41af-d5d5-62f927ef2158"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sample 1:\n","Input: 창성해물손칼국수의 대표적인 메뉴를 알 수 있나요?\n","Predicted: 창성해물손칼국수의 메뉴에는 해물칼국수, 해물수제비가 있습니다\n","Target: 창성해물손칼국수의 메뉴에는 해물칼국수, 해물수제비가 있습니다\n","\n","Sample 2:\n","Input: 족팔계의 영업시간은 어떻게 되나요?\n","Predicted: 도깨비굴의 영업시간은 11:00 - 21:00입니다\n","Target: 족팔계의 영업시간은 16:00 - 01:30입니다\n","\n","Sample 3:\n","Input: 정화네동태국의 주차시설이 있는지 알 수 있나요?\n","Predicted: 정화네동태국의 위치는 서울 동대문구 왕산로 254 1층입니다\n","Target: 정화네동태국의 주차시설은 있습니다\n","\n","Sample 4:\n","Input: 플랫커피의 주차시설이 있는지 알 수 있나요?\n","Predicted: 도화루중화요리의 메뉴에는 홍어회, 떡볶이가 있습니다\n","Target: 플랫커피의 주차시설은 없습니다\n","\n","Sample 5:\n","Input: 명륜진사갈비 신정네거리점의 위치를 알 수 있나요?\n","Predicted: 명륜진사갈비 신정네거리점의 위치는 서울 양천구 중앙로 222입니다\n","Target: 명륜진사갈비 신정네거리점의 위치는 서울 양천구 중앙로 222입니다\n","\n","Sample 6:\n","Input: 논밭골 봉천점의 영업시간은 어떻게 되나요?\n","Predicted: 논밭골 봉천점의 위치는 서울 관악구 청룡길 30입니다\n","Target: 논밭골 봉천점의 영업시간은 10:40 - 24:00입니다\n","\n","Sample 7:\n","Input: 영등포구 맛집 추천좀\n","Predicted: 영등포구의 맛집으로는 도도포차에 가보세요\n","Target: 영등포구의 맛집으로는 꽃담식당를 추천드립니다\n","\n","Sample 8:\n","Input: 은평구 맛집 추천좀\n","Predicted: 은평구의 맛집으로는 도화에 가보세요\n","Target: 은평구의 맛집으로는 연탄 생고기집 대조점이 알려져 있습니다\n","\n","Sample 9:\n","Input: 아날로그소사이어티키친의 연락처가 어떻게 되나요?\n","Predicted: 아날로그소사이어티키친의 메뉴에는 바질 페스토 스파게티, 게 스파게티가 있습니다\n","Target: 아날로그소사이어티키친의 연락처는 0507-1385-5003입니다\n","\n","Sample 10:\n","Input: 숙이네반주집의 휴무일을 알 수 있나요?\n","Predicted: 숙달돼지 잠실방이점의 위치는 서울 송파구 오금로13길 10-1입니다\n","Target: 숙이네반주집의 휴무일은 알수없습니다\n","Evaluation complete!\n"]}]},{"cell_type":"code","source":["dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n","optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","\n","# 학습\n","num_epochs = 20\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","\n","    for batch in dataloader:\n","        src_batch, tgt_batch = batch\n","\n","        src_batch = src_batch.to(device)\n","        tgt_batch = tgt_batch.to(device)\n","\n","        tgt_input = tgt_batch[:, :-1]\n","        tgt_output = tgt_batch[:, 1:]\n","\n","        src_key_padding_mask = (src_batch == pad_token_id).to(device)\n","        tgt_key_padding_mask = (tgt_input == pad_token_id).to(device)\n","\n","        optimizer.zero_grad()\n","\n","        with autocast():\n","            output = model(src_batch, tgt_input,\n","                       src_key_padding_mask=src_key_padding_mask,\n","                       tgt_key_padding_mask=tgt_key_padding_mask)\n","            loss = criterion(output.contiguous().view(-1, vocab_size), tgt_output.contiguous().view(-1))\n","\n","        scaler.scale(loss).backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        epoch_loss += loss.item()\n","\n","    avg_loss = epoch_loss / len(dataloader)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.6f}\")\n","\n","    early_stopping(avg_loss, model)\n","    if early_stopping.stopped_early:\n","        break\n","\n","print(\"Training complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bNXxjNaum-3J","executionInfo":{"status":"ok","timestamp":1721990399242,"user_tz":-540,"elapsed":1319834,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"079b1a39-91dc-4dc3-f592-82a571e034d8"},"execution_count":119,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Train Loss: 0.057340\n","Epoch 2/20, Train Loss: 0.055851\n","Epoch 3/20, Train Loss: 0.055248\n","Epoch 4/20, Train Loss: 0.054614\n","Epoch 5/20, Train Loss: 0.050829\n","Epoch 6/20, Train Loss: 0.050559\n","Epoch 7/20, Train Loss: 0.049952\n","Epoch 8/20, Train Loss: 0.049694\n","Epoch 9/20, Train Loss: 0.049510\n","Epoch 10/20, Train Loss: 0.049437\n","Epoch 11/20, Train Loss: 0.049109\n","Epoch 12/20, Train Loss: 0.048997\n","Epoch 13/20, Train Loss: 0.048719\n","Epoch 14/20, Train Loss: 0.047074\n","Epoch 15/20, Train Loss: 0.046247\n","Epoch 16/20, Train Loss: 0.046245\n","Epoch 17/20, Train Loss: 0.045991\n","Epoch 18/20, Train Loss: 0.045848\n","Epoch 19/20, Train Loss: 0.045529\n","Epoch 20/20, Train Loss: 0.045479\n","Training complete!\n"]}]},{"cell_type":"code","source":["# 평가\n","model.eval()\n","generated_texts = []\n","target_texts = []\n","\n","try:\n","    with torch.no_grad():\n","        # 첫 번째 배치만 가져옵니다\n","        batch = next(iter(dataloader))\n","        src_batch, tgt_batch = batch\n","        src_batch = src_batch.to(device)\n","        tgt_batch = tgt_batch.to(device)\n","\n","        for i, (src_single, tgt_single) in enumerate(zip(src_batch, tgt_batch)):\n","            generated = generate_text(model, src_single.unsqueeze(0), tokenizer, max_length=100, device=device)\n","\n","            input_text = tokenizer.decode(src_single.cpu().numpy(), skip_special_tokens=True)\n","            predicted_text = decode_output(generated.cpu().numpy(), tokenizer)\n","            target_text = tokenizer.decode(tgt_single.cpu().numpy(), skip_special_tokens=True)\n","\n","            print(f\"\\nSample {i+1}:\")\n","            print(f\"Input: {input_text}\")\n","            print(f\"Predicted: {predicted_text}\")\n","            print(f\"Target: {target_text}\")\n","\n","            generated_texts.append(predicted_text)\n","            target_texts.append(target_text)\n","\n","            if i == 9:\n","                break\n","\n","except Exception as e:\n","    print(f\"An error occurred during evaluation: {str(e)}\")\n","\n","print(\"Evaluation complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ouSyU8zruVpt","executionInfo":{"status":"ok","timestamp":1721990467442,"user_tz":-540,"elapsed":5260,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"d06db20b-48c5-496d-b518-a65abd990f3d"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sample 1:\n","Input: 할매떡볶이에 인접한 시설이 있나요?\n","Predicted: 할매떡볶이에 인접한 시설에는 사직역 3번 출구, 농협하나로클럽, 스타벅스가 있습니다\n","Target: 할매떡볶이에 인접한 시설에는 사직역 3번 출구, 농협하나로클럽, 스타벅스가 있습니다\n","\n","Sample 2:\n","Input: 깐부치킨 뚝섬유원지점의 메뉴를 알 수 있나요?\n","Predicted: 깐부치킨 선유도역점의 메뉴에는 크런치 찰 핫도그, 빠삭커리네윙봉이 있습니다\n","Target: 깐부치킨 뚝섬유원지점의 메뉴에는 깐부 해물짬뽕탕, 크런치 찰 핫도그가 있습니다\n","\n","Sample 3:\n","Input: 소담촌 용두점의 휴무일이 어떻게 되나요?\n","Predicted: 소담촌 아차산역점의 휴무일은 없습니다\n","Target: 소담촌 용두점의 휴무일은 없습니다\n","\n","Sample 4:\n","Input: 태양부양꼬치 시흥점의 위치를 알 수 있나요?\n","Predicted: 태양부양꼬치 시흥점의 위치는 서울 금천구 은행나무로 51입니다\n","Target: 태양부양꼬치 시흥점의 위치는 서울 금천구 은행나무로 51입니다\n","\n","Sample 5:\n","Input: 히치케이커의 대표적인 메뉴는 무엇이 있나요?\n","Predicted: 히포슈가 송파본점의 메뉴에는 플레인 팬케이크, 루꼴라 리코타 샐러드 팬케이크가 있습니다\n","Target: 히치케이커의 메뉴에는 아이스아메리카노, 바닐라라떼가 있습니다\n","\n","Sample 6:\n","Input: 성동구 맛집 추천 부탁해\n","Predicted: 성동구의 맛집으로는 에롤파가 있습니다\n","Target: 성동구의 맛집으로는 성수피글렛를 추천드립니다\n","\n","Sample 7:\n","Input: 목탄장 여의도점의 주차시설이 있는지 알 수 있나요?\n","Predicted: 목탄장 여의도점의 메뉴에는 구운 포카치아, 과일 단새우가 있습니다\n","Target: 목탄장 여의도점의 주차시설은 있습니다\n","\n","Sample 8:\n","Input: 바르다김선생 당산역점에 인접한 시설이 있나요?\n","Predicted: 바르다김선생 당산역점에 인접한 시설에는 당산역 12번 출구, 메가커피, 맘스터치가 있습니다\n","Target: 바르다김선생 당산역점에 인접한 시설에는 당산역 12번 출구, 메가커피, 맘스터치가 있습니다\n","\n","Sample 9:\n","Input: 뜰아래의 대표적인 메뉴를 알 수 있나요?\n","Predicted: 뜰아래의 메뉴에는 매운갈비찜, 궁중갈비찜이 있습니다\n","Target: 뜰아래의 메뉴에는 매운갈비찜, 궁중갈비찜이 있습니다\n","\n","Sample 10:\n","Input: 덮세권의 대표적인 메뉴는 무엇이 있나요?\n","Predicted: 덮세권의 메뉴에는 부타동, 규동가 있습니다\n","Target: 덮세권의 메뉴에는 부타동, 규동가 있습니다\n","Evaluation complete!\n"]}]},{"cell_type":"code","source":["# 메인 루프\n","def main(model, tokenizer, device):\n","    while True:\n","        question = input(\"질문을 입력하세요 (종료하려면 '나가기' 입력): \")\n","        if question.strip() == '나가기':\n","            print(\"프로그램을 종료합니다.\")\n","            break\n","\n","        # 질문을 토크나이즈\n","        input_ids = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n","\n","        # 응답 생성\n","        response_ids = generate_text(model, input_ids, tokenizer, device=device)\n","\n","        # 응답 디코딩\n","        response = tokenizer.decode(response_ids, skip_special_tokens=True)\n","        print(f\"답변: {response}\\n\")\n","\n","main(model, tokenizer, device)"],"metadata":{"id":"ycWvhrkgCKik","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721991112027,"user_tz":-540,"elapsed":630059,"user":{"displayName":"gosling","userId":"04922823008265108443"}},"outputId":"7b54e76b-737e-4c0a-c60a-61c95adc3536"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["질문을 입력하세요 (종료하려면 '나가기' 입력): 덮세권의 대표적인 메뉴는 무엇이 있나요?\n","답변: 덮세권의 메뉴에는 부타동, 규동가 있습니다\n","\n","질문을 입력하세요 (종료하려면 '나가기' 입력): 성동구 맛집 추천 부탁해\n","답변: 성동구의 맛집으로는 히어를 추천드립니다\n","\n","질문을 입력하세요 (종료하려면 '나가기' 입력): 히치케이커의 대표적인 메뉴는 무엇이 있나요?\n","답변: 히치케이커의 메뉴에는 아이스아메리카노, 바닐라라떼가 있습니다\n","\n","질문을 입력하세요 (종료하려면 '나가기' 입력): 태양부양꼬치 시흥점의 위치를 알 수 있나요?\n","답변: 태양부양꼬치 시흥점의 위치는 서울 금천구 은행나무로 51입니다\n","\n","질문을 입력하세요 (종료하려면 '나가기' 입력): 나가기\n","프로그램을 종료합니다.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_GMyPuyT300E"},"execution_count":null,"outputs":[]}]}